{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from scipy import signal\n",
    "from scipy.stats import norm, pearsonr\n",
    "from itertools import combinations\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database full path\n",
    "database_name = 'whistlers.h5'\n",
    "database_location = os.path.join(os.getcwd().split(os.environ.get('USER'))[0],os.environ.get('USER'), 'wdml', 'Data')\n",
    "database_path = os.path.join(database_location,database_name)\n",
    "\n",
    "# data variables\n",
    "awd_events = 2\n",
    "sites = ['marion', 'sanae']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spectrogram_info(spectrogram_data):\n",
    "    '''Extract the time, frequency axis values as well as the \n",
    "            spectrogram data.\n",
    "    inputs:\n",
    "        spectrogram_data: the spectrogram data including the \n",
    "        time and frequency information.\n",
    "    outputs: \n",
    "        time: time values\n",
    "        frequency: frequency values\n",
    "        spectrogram: spectrogram\n",
    "    '''\n",
    "    time = spectrogram_data[0,1:]\n",
    "    frequency = spectrogram_data[1:,0]\n",
    "    spectrogram = spectrogram_data[1:,1:]\n",
    "    return time, frequency, spectrogram\n",
    "\n",
    "def reshape_spectrogram(f, t, s):\n",
    "    f = np.asarray(f)\n",
    "    t = np.asarray(t)\n",
    "    s = np.asarray(s)\n",
    "    _t = np.concatenate(([0],t))\n",
    "    _s = np.concatenate((f[np.newaxis].T,s), axis=1)\n",
    "    sft = np.vstack((_t,_s))\n",
    "    return sft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_durations = []\n",
    "# site_recording_frq = 257\n",
    "# for awd_event in range(1,awd_events):\n",
    "#     for site in range(len(sites)):\n",
    "#         temp = []\n",
    "#         f  = h5py.File(database_path, 'r')\n",
    "#         grp_wh = f[os.path.join('awdEvents'+str(awd_event), sites[site],'split_dataset')]\n",
    "#         files = list(grp_wh.keys())\n",
    "#         for file in files:\n",
    "#             temp.append(grp_wh[file].shape[1])\n",
    "#         f.close()\n",
    "#         file_durations.append(np.asarray(temp))\n",
    "# site_recording_time = []\n",
    "# gaussian_site_noise = []\n",
    "# gaussian_mean = (0,0)\n",
    "# gaussian_cov = [[0,0],[0,1]]\n",
    "\n",
    "# for site in range(len(sites)):\n",
    "#     site_recording_time.append(file_durations[site].max())\n",
    "#     gaussian_site_noise.append(np.random.multivariate_normal(gaussian_mean, gaussian_cov, \n",
    "#                                                              (site_recording_frq, site_recording_time[site]))[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_recording_frq = 257\n",
    "site_recording_time = [2630, 1262]\n",
    "gaussian_site_noise = []\n",
    "gaussian_mean = (0,0)\n",
    "gaussian_cov = [[0,0],[0,1]]\n",
    "for site in range(len(sites)):\n",
    "    gaussian_site_noise.append(np.random.multivariate_normal(gaussian_mean, gaussian_cov, \n",
    "                                                             (site_recording_frq, site_recording_time[site]))[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vstack_uneven(base_arr, added_arr):\n",
    "    index = added_arr.shape[1]\n",
    "    arr = np.zeros(shape=base_arr.shape)\n",
    "    arr[:,:index] = added_arr + base_arr[:,:index]\n",
    "    arr[:,index:] = base_arr[:,index:]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating split dataset gaussian for awdEvent1/marion\n",
      "0%.........10%.........20%....."
     ]
    }
   ],
   "source": [
    "for awd_event in range(1,awd_events):\n",
    "    for site in range(len(sites)):\n",
    "        data = []\n",
    "        indexes = []\n",
    "        columns = list(range(site_recording_time[site]*site_recording_frq))\n",
    "        columns.append('event')\n",
    "        f  = h5py.File(database_path, 'r+')\n",
    "        grp = f[os.path.join('awdEvents'+str(awd_event), sites[site],'split_dataset')]\n",
    "#         grp_split = f.require_group(os.path.join('awdEvents'+str(awd_event), sites[site],'split_dataset_gaussian'))\n",
    "        files = list(grp.keys())\n",
    "        # file = files[np.random.randint(len(files))] # select a random sample\n",
    "        # file = '2013-07-29UT14:22:21.36931914.marion.vr2'\n",
    "        print('\\nGenerating split dataset gaussian for %s/%s' %('awdEvent'+str(awd_event),sites[site]))\n",
    "        last_percent = None\n",
    "        num_file = 0\n",
    "        _range = range(int(len(files)))\n",
    "#         print(_range)\n",
    "        for num_file in _range:\n",
    "#             print(num_file)\n",
    "            file = files[num_file]\n",
    "            file_data = np.empty(grp[file].shape, dtype=np.float32)\n",
    "            grp[file].read_direct(file_data)\n",
    "            # extract spectrogram\n",
    "            _t,_f,Sxx = extract_spectrogram_info(file_data)\n",
    "            # add noise\n",
    "            Sxx = vstack_uneven(gaussian_site_noise[site], Sxx)\n",
    "            Sxx = Sxx.flatten()\n",
    "            # reduce by the mean\n",
    "            Sxx = Sxx.tolist()\n",
    "            # add event boolean\n",
    "            Sxx.append(grp[file].attrs['event'])\n",
    "            # update data and indexes\n",
    "            data.append(Sxx)\n",
    "            indexes.append(file)\n",
    "            # print progress\n",
    "            percent = int(num_file*100/len(files))\n",
    "            if last_percent != percent:\n",
    "                if percent%10==0:\n",
    "                    sys.stdout.write(\"%s%%\" % percent)\n",
    "                    sys.stdout.flush()\n",
    "                else:\n",
    "                    sys.stdout.write(\".\")\n",
    "                    sys.stdout.flush()\n",
    "                last_percent = percent\n",
    "        print(\"\\nAdding to DataFrame\")\n",
    "        data_frame = pd.DataFrame.from_records(data, indexes, columns=columns)\n",
    "        data = []\n",
    "        indexes = []\n",
    "        print(\"Added to DataFrame\")\n",
    "#         database_name = 'whistler_events_'+sites[site]+'.h5'\n",
    "#         database_path = os.path.join(database_location,database_name)\n",
    "#         data_frame.to_hdf(database_path, key=sites[site])\n",
    "        f.close()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_frame.loc[:, data_frame.columns != 'event']\n",
    "Y = data_frame.loc[:, 'event']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components=0.80)\n",
    "X = pca.fit_transform(X)\n",
    "print(pca.explained_variance_ratio_.shape)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To getter a better understanding of interaction of the dimensions\n",
    "# plot the first three PCA dimensions\n",
    "fig = plt.figure(1, figsize=(8, 6))\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=Y,\n",
    "           cmap=plt.cm.Set1, edgecolor='k', s=20)\n",
    "ax.set_title(\"First three PCA directions\")\n",
    "ax.set_xlabel(\"1st eigenvector\")\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.set_ylabel(\"2nd eigenvector\")\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.set_zlabel(\"3rd eigenvector\")\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, cmap=plt.cm.Set1,edgecolor='k')\n",
    "plt.xlabel(\"1st eigenvector\")\n",
    "plt.ylabel(\"2nd eigenvector\")\n",
    "plt.subplot(1,3,2)\n",
    "plt.scatter(X[:, 0], X[:, 2], c=Y, cmap=plt.cm.Set1,edgecolor='k')\n",
    "plt.xlabel(\"1st eigenvector\")\n",
    "plt.ylabel(\"3rd eigenvector\")\n",
    "plt.subplot(1,3,3)\n",
    "plt.scatter(X[:, 1], X[:, 2], c=Y, cmap=plt.cm.Set1,edgecolor='k')\n",
    "plt.xlabel(\"2nd eigenvector\")\n",
    "plt.ylabel(\"3rd eigenvector\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_pca = decomposition.PCA().fit(X)\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(_pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
