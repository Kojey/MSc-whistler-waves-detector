{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from scipy import signal\n",
    "from scipy.stats import norm, pearsonr\n",
    "from itertools import combinations\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database full path\n",
    "database_name = 'whistlers.h5'\n",
    "database_location = os.path.join(os.getcwd().split(os.environ.get('USER'))[0],os.environ.get('USER'), 'wdml', 'Data')\n",
    "database_path = os.path.join(database_location,database_name)\n",
    "\n",
    "# data variables\n",
    "awd_events = 2\n",
    "sites = ['marion', 'sanae']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spectrogram_info(spectrogram_data):\n",
    "    '''Extract the time, frequency axis values as well as the \n",
    "            spectrogram data.\n",
    "    inputs:\n",
    "        spectrogram_data: the spectrogram data including the \n",
    "        time and frequency information.\n",
    "    outputs: \n",
    "        time: time values\n",
    "        frequency: frequency values\n",
    "        spectrogram: spectrogram\n",
    "    '''\n",
    "    time = spectrogram_data[0,1:]\n",
    "    frequency = spectrogram_data[1:,0]\n",
    "    spectrogram = spectrogram_data[1:,1:]\n",
    "    return time, frequency, spectrogram\n",
    "\n",
    "def reshape_spectrogram(f, t, s):\n",
    "    f = np.asarray(f)\n",
    "    t = np.asarray(t)\n",
    "    s = np.asarray(s)\n",
    "    _t = np.concatenate(([0],t))\n",
    "    _s = np.concatenate((f[np.newaxis].T,s), axis=1)\n",
    "    sft = np.vstack((_t,_s))\n",
    "    return sft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_no_event = np.array([0,0])\n",
    "nb_event = np.array([0,0])\n",
    "nb_file = np.array([0,0])\n",
    "for awd_event in range(1,awd_events):\n",
    "    for site in range(len(sites)):\n",
    "        f  = h5py.File(database_path, 'r+')\n",
    "        grp_wh = f[os.path.join('awdEvents'+str(awd_event), sites[site],'spectrograms')]\n",
    "        grp_split = f.require_group(os.path.join('awdEvents'+str(awd_event), sites[site],'split_dataset'))\n",
    "        files = list(grp_wh.keys())\n",
    "        nb_file[site] = len(files)\n",
    "        # file = files[np.random.randint(len(files))] # select a random sample\n",
    "        # file = '2013-07-29UT14:22:21.36931914.marion.vr2'\n",
    "        print('\\nGenerating split dataset for %s/%s' %('awdEvent'+str(awd_event),sites[site]))\n",
    "        last_percent = None\n",
    "        num_file = 0\n",
    "        for num_file in range(len(files)):\n",
    "            file_index = 0\n",
    "            file = files[num_file]\n",
    "            # print(file)\n",
    "            # create np array to store sample information\n",
    "            data = np.empty(grp_wh[file].shape)\n",
    "            grp_wh[file].read_direct(data)\n",
    "            outputs = grp_wh[file].attrs['output']\n",
    "            # extract data info\n",
    "            time, freq, Sxx = extract_spectrogram_info(data)\n",
    "            _t = np.round_(time,decimals=3)\n",
    "            index = 0\n",
    "            indices = []\n",
    "            for output in outputs:\n",
    "                event_time = np.round(output[0]/1000,3)\n",
    "                # find the index in the time \n",
    "                index = min(range(len(_t)), key=lambda i: abs(_t[i]-event_time))\n",
    "                # only process if the index found is new\n",
    "                if index!=0 and index not in indices:\n",
    "                    indices.append(index)\n",
    "\n",
    "            # add probabilities to evetns\n",
    "            events = sorted(outputs[:,1], reverse=True)[:len(indices)] # map prob to to event correctly\n",
    "\n",
    "            # add last index of time to indices and permute the indices into sets of 2\n",
    "            indices.append(time.shape[0])\n",
    "            event_indices = list(combinations(indices,2))\n",
    "\n",
    "            # get eventless section of spectrogram\n",
    "            Sxx_no_event, dump = np.hsplit(Sxx, [indices[0]])\n",
    "            t_no_event, dump = np.hsplit(time, [indices[0]])\n",
    "            # add to dataset\n",
    "            spec_data = reshape_spectrogram(freq, t_no_event, Sxx_no_event)\n",
    "            file_name = file.split('.vr2')[0]+'_'+ str(file_index)+'.vr2'\n",
    "            file_dataset = grp_split.create_dataset(file_name,spec_data.shape,np.float32, compression=\"gzip\", data=spec_data)\n",
    "            file_dataset.attrs['event'] = False\n",
    "            nb_no_event[site] += 1\n",
    "            \n",
    "            # for each set of events\n",
    "            for i in event_indices:\n",
    "                # extract events\n",
    "                file_index += 1\n",
    "                Sxx_event = Sxx[:,i[0]:i[1]]\n",
    "                t_event = time[i[0]:i[1]]\n",
    "                spec_data = reshape_spectrogram(freq, t_event, Sxx_event)\n",
    "                # create dataset\n",
    "                file_name = file.split('.vr2')[0]+'_'+ str(file_index)+'.vr2'\n",
    "                file_dataset = grp_split.create_dataset(file_name,spec_data.shape,np.float32, compression=\"gzip\", data=spec_data)\n",
    "                file_dataset.attrs['event'] = True\n",
    "                nb_event[site] += 1\n",
    "            \n",
    "            # print progress\n",
    "            percent = int(num_file*100/len(files))\n",
    "            if last_percent != percent:\n",
    "                if percent%10==0:\n",
    "                    sys.stdout.write(\"%s%%\" % percent)\n",
    "                    sys.stdout.flush()\n",
    "                else:\n",
    "                    sys.stdout.write(\".\")\n",
    "                    sys.stdout.flush()\n",
    "                last_percent = percent\n",
    "        f.close()\n",
    "        \n",
    "print('Number of datasets without event:', nb_no_event.sum())\n",
    "print('Number of datasets with event:', nb_event.sum())\n",
    "print('Number of datasets :', nb_file.sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
