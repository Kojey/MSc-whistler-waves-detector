{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store outputs in a database\n",
    "Each output database contains the follwing:\n",
    "* events attribute: the number of event in the datafile\n",
    "* a 2D array with:\n",
    "    * row 1: the time difference (in ms) between the event and the start of the reccording (found in the file's name)\n",
    "    * row 2: probability associated with the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database full path\n",
    "database_name = 'whistlers.h5'\n",
    "database_location = os.path.join(os.getcwd().split(os.environ.get('USER'))[0],os.environ.get('USER'), 'wdml', 'Data')\n",
    "database_path = os.path.join(database_location,database_name)\n",
    "\n",
    "# data variables\n",
    "awd_events = 2\n",
    "sites = ['marion', 'sanae']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_output(data_root, awd_event, site):\n",
    "    \"\"\"Extract the output information for each file\n",
    "    inputs\n",
    "        data_root   location of the data\n",
    "        site        site where data was collected\n",
    "    outputs\n",
    "        dataset     dictionary mapping each file with the whistler location\n",
    "    \"\"\"\n",
    "    output_path = os.path.join(data_root,site)\n",
    "    output_file = None\n",
    "    for file in os.listdir(output_path):\n",
    "        if file.endswith('.out'):\n",
    "            output_file = file\n",
    "            break\n",
    "    try:\n",
    "        os.path.exists(output_file)\n",
    "        with open(os.path.join(output_path, output_file), 'r') as f:\n",
    "            dataset = {}\n",
    "            num_line = 0\n",
    "            lines = f.readlines()\n",
    "            file_list = []\n",
    "            last_percent = None\n",
    "            print('\\nGenerating outputs for %s/%s' %('awdEvent'+str(awd_event),site))\n",
    "            for line in lines:\n",
    "                event = {}\n",
    "                line = line.split('\\n') # Remove the '\\n' character from each line\n",
    "                line = line[0].split(' ') \n",
    "                line = list(filter(None, line)) # discard empty element in array\n",
    "                for index in range(2,len(line),2): # store event and probabilities in a dictionary\n",
    "                    event[line[index]]=line[index+1]\n",
    "                # save the dictionary\n",
    "                if line[1] not in file_list: # if file name not in the list\n",
    "                    dataset[line[1]]=event\n",
    "                    file_list.append(line[1])\n",
    "                else:\n",
    "                    data = dataset[line[1]]\n",
    "                    event.update(data)\n",
    "                    dataset[line[1]]=event\n",
    "                # print progression\n",
    "                percent = int(num_line*100/len(lines))\n",
    "                if last_percent != percent:\n",
    "                    if percent%5==0:\n",
    "                        sys.stdout.write(\"%s%%\" % percent)\n",
    "                        sys.stdout.flush()\n",
    "                    else:\n",
    "                        sys.stdout.write(\".\")\n",
    "                        sys.stdout.flush()\n",
    "                    last_percent = percent\n",
    "                num_line+=1\n",
    "    except Exception as e:\n",
    "        print('Error:', e)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime_to_unit(datatime):\n",
    "    times = datatime.split('UT')\n",
    "    h, m, ss = times[-1].split(':')\n",
    "    s, u = ss.split('.')\n",
    "    return [h,m,s,u]\n",
    "def datetime_to_ms(datetime):\n",
    "    datetime = datetime_to_unit(datetime)\n",
    "    datetime[0] = float(datetime[0])*60*60*1000\n",
    "    datetime[1] = float(datetime[1])*60*1000\n",
    "    datetime[2] = float(datetime[2])*1000\n",
    "    datetime[3] = float(datetime[3])/10**(len(datetime[3]))\n",
    "    return sum(datetime)\n",
    "def datetime_diff(datetime2, datetime1):\n",
    "    return datetime_to_ms(datetime2)-datetime_to_ms(datetime1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating outputs for awdEvent1/marion\n",
      "0%.........10%.........20%.........30%.........40%.........50%.........60%.........70%.........80%.........90%.........\n",
      "Generating outputs for awdEvent1/sanae\n",
      "0%.........10%.........20%.........30%.........40%.........50%.........60%.........70%.........80%.........90%........."
     ]
    }
   ],
   "source": [
    "for awd_event in range(1,awd_events):\n",
    "    for site in sites:\n",
    "        f = h5py.File(database_path, 'a')\n",
    "        f.require_group('awdEvents%s/%s/outputs' % (str(awd_event), site))    \n",
    "        grp = f[os.path.join('awdEvents'+str(awd_event),site,'outputs')]\n",
    "        # find output file\n",
    "        output_path = os.path.join(database_location, 'awdEvents'+str(awd_event), site)\n",
    "        output_file = None\n",
    "        for file in os.listdir(output_path):\n",
    "            if file.endswith('_no_duplicate.out'):\n",
    "                output_file = file\n",
    "                break        \n",
    "        # extract output\n",
    "        try:\n",
    "            os.path.exists(output_file)\n",
    "            with open(os.path.join(output_path, output_file), 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                file_list = []\n",
    "                last_percent = None\n",
    "                num_file = 0\n",
    "                print('\\nGenerating outputs for %s/%s' %('awdEvent'+str(awd_event),site))\n",
    "                for line in lines:\n",
    "                    line = line.split('\\n') # Remove the '\\n' character from each line\n",
    "                    line = line[0].split(' ')\n",
    "                    line = list(filter(None, line)) # discard empty element in array\n",
    "                    file = line[1]\n",
    "                    file_time = file[:27]\n",
    "                    output = []\n",
    "                    for index in range(2,len(line),2): # store event and probabilities in a dictionary\n",
    "                        output.append([round(datetime_diff(line[index],file_time),5),float(line[index+1])])\n",
    "                    # sort output based on time\n",
    "                    output = sorted(output, key=lambda x:x[0])\n",
    "                    output = np.asarray(output)\n",
    "                    # save the dictionary\n",
    "                    file_dataset = grp.create_dataset(file,output.shape,np.float32, compression=\"gzip\", data=output)\n",
    "                    file_dataset.attrs['events'] = len(output[:,0])\n",
    "                    \n",
    "                    percent = int(num_file*100/len(lines))\n",
    "                    if last_percent != percent:\n",
    "                        if percent%10==0:\n",
    "                            sys.stdout.write(\"%s%%\" % percent)\n",
    "                            sys.stdout.flush()\n",
    "                        else:\n",
    "                            sys.stdout.write(\".\")\n",
    "                            sys.stdout.flush()\n",
    "                        last_percent = percent\n",
    "                    num_file+=1\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print('Error:', e) \n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
