{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-06-09UT12:52:37.22969609.marion.vr2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 200x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2013-06-09UT12:52:37.22969609.marion.vr2'\n",
      " array([[array([ 2.54647964, 10.27165075]), 0],\n",
      "       [array([ 3.06473303, 10.38458628]), 0],\n",
      "       [array([ 4.64508597, 10.5452116 ]), 0],\n",
      "       [array([ 5.15694118, 11.03268269]), 0],\n",
      "       [array([8.07451584, 9.34757823]), 0],\n",
      "       [array([9.16860633, 9.63007175]), 0],\n",
      "       [array([ 5.6463, 59.    ]), -1],\n",
      "       [array([ 9.6803, 92.    ]), -1]], dtype=object)\n",
      " array([2, 6, 0])]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import h5py\n",
    "import glob\n",
    "import tqdm\n",
    "import time \n",
    "import pickle\n",
    "import numpy as np\n",
    "from matplotlib import image\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "\n",
    "# import python library\n",
    "sys.path.append(os.path.join(os.getcwd().split(os.environ.get('USER'))[0],os.environ.get('USER'), 'wdml', 'py'))\n",
    "\n",
    "from sample_detector import SampleDetector\n",
    "from database import Database\n",
    "\n",
    "class Detector(Database):\n",
    "    # Attributes\n",
    "    __train, __test = None, None\n",
    "    __train_test_file = 'train_test.pickle'\n",
    "    __dataset_location = None\n",
    "    __result_location = None\n",
    "    __site = None\n",
    "    # Initializer\n",
    "    def __init__(self, dataset_location, database_location, result_location, site):\n",
    "        self.__dataset_location = dataset_location\n",
    "        self.__result_location = result_location\n",
    "        self.__site = site\n",
    "        super().__init__(dataset_location, database_location, site)\n",
    "    \n",
    "    def evaluate_detector(self,args):\n",
    "        sample = args[0]\n",
    "        return sample.evaluate_detector(transforms=args[1], transforms_params=args[2], \n",
    "                                        detector=args[3], detector_params=args[4],\n",
    "                                        diff_err=args[5], time_err=args[6],\n",
    "                                        kernel=args[7])\n",
    "    \n",
    "    def generate_kernel(self, sample, whistler, whislter_params):\n",
    "        if whistler=='sim':\n",
    "            return sample.whistler_sim(decay=whislter_params[0], \n",
    "                                       whistler_time=whislter_params[1], \n",
    "                                       whistler_freq_len=whislter_params[2], \n",
    "                                       whistler_freq_start=whislter_params[3], \n",
    "                                       thickness=whislter_params[4],\n",
    "                                       size=whislter_params[5])\n",
    "    \n",
    "    def detector_metric(self, train, transforms, transforms_params, detector, detector_params, diff_err, time_err,\n",
    "                         whistler, whistler_params, save=False):\n",
    "        # get files from either train or test\n",
    "        files = self.get_train() if train else self.get_test()\n",
    "        samples = np.array([SampleDetector(self.__dataset_location, self.__site, file) for file in files])#[int(len(files)*0.297):int(len(files)*0.299)]\n",
    "        assert len(samples)>0, 'No samples'\n",
    "        # generate kernel\n",
    "        kernel = self.generate_kernel(samples[0],whistler, whistler_params)\n",
    "        # create multiprocessing methods\n",
    "        pool = mp.Pool(mp.cpu_count())\n",
    "        params = [[sample, transforms, transforms_params, detector, detector_params, diff_err, time_err, kernel] for sample in samples]\n",
    "        results = []\n",
    "        for result in tqdm.tqdm(pool.imap_unordered(self.evaluate_detector, params), total=len(params)):\n",
    "            results.append(result)\n",
    "        results = np.array(results)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        if save:\n",
    "            self.save_detector_metric(train, transforms, transforms_params, detector, detector_params, diff_err, time_err,\n",
    "                         whistler, whistler_params, results)\n",
    "        return results\n",
    "    \n",
    "    def save_detector_metric(self, train, transforms, transforms_params, detector, detector_params, diff_err, time_err,\n",
    "                         whistler, whistler_params, results):\n",
    "        #create parameters dictionary\n",
    "        data = {\n",
    "            'transforms': transforms,\n",
    "            'transforms_params': transforms_params, \n",
    "            'detector': detector, \n",
    "            'detector_params': detector_params,\n",
    "            'whistler': whistler,\n",
    "            'whistler_params': whistler_params, \n",
    "            'diff_err': diff_err, \n",
    "            'time_err': time_err,\n",
    "            'results': results\n",
    "        }\n",
    "        path = os.path.join(self.__result_location,self.get_site())\n",
    "        try:\n",
    "            os.makedirs(path)\n",
    "        except OSError:\n",
    "            pass\n",
    "        file_name = '_'.join([str(train),str(transforms),str(transforms_params),str(detector),\n",
    "                     str(detector_params),str(diff_err),str(time_err),str(whistler),str(whistler_params)])\n",
    "        file_name += '.result'\n",
    "        pickle.dump(data, open(os.path.join(path,file_name), 'wb'))\n",
    "    \n",
    "    def load_detector_metric(self,train, transforms, transforms_params, detector, detector_params, diff_err, time_err,\n",
    "                         whistler, whistler_params):\n",
    "        file_name = '_'.join([str(train),str(transforms),str(transforms_params),str(detector),\n",
    "                     str(detector_params),str(diff_err),str(time_err),str(whistler),str(whistler_params)])\n",
    "        file_name += '.result'\n",
    "        path = os.path.join(self.__result_location,self.get_site(),file_name)\n",
    "        if not os.path.exists(path):\n",
    "            raise Exception('%s does not exists.'%path)\n",
    "        return pickle.load( open(path, \"rb\"))\n",
    "    \n",
    "    def results(self, results):\n",
    "        results = np.array([r for r in results[:,2]])\n",
    "        return results[:,0].sum(),results[:,1].sum(),results[:,2].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1471/1471 [01:43<00:00, 13.32it/s]\n",
      "100%|██████████| 1471/1471 [01:42<00:00, 13.12it/s]\n",
      "100%|██████████| 1471/1471 [01:45<00:00,  9.15it/s]\n",
      "100%|██████████| 1471/1471 [01:40<00:00, 14.67it/s]\n",
      "100%|██████████| 1471/1471 [01:41<00:00, 13.25it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_loc = os.path.join(os.getcwd().split(os.environ.get('USER'))[0],os.environ.get('USER'), 'wdml', 'data','datasets', 'awdEvents1')\n",
    "database_loc = os.path.join(os.getcwd().split(os.environ.get('USER'))[0],os.environ.get('USER'), 'wdml', 'data','databases', 'awdEvents1')\n",
    "result_loc = os.path.join(os.getcwd().split(os.environ.get('USER'))[0],os.environ.get('USER'), 'wdml', 'data','results', 'awdEvents1')\n",
    "site = 'marion'\n",
    "my_detector = Detector(dataset_loc, database_loc, result_loc, site)\n",
    "my_sample = SampleDetector(dataset_loc, site, np.random.choice(my_detector.get_train(),1)[0])\n",
    "\n",
    "for w in [0.5,0.65,0.8,1,1.5]:\n",
    "    my_detector.detector_metric(train=True, transforms=['zscore'], transforms_params=[[None]], detector='tm_cfar', \n",
    "                            detector_params=[10,15,1e-3,0], diff_err=0.3, time_err=0.2, whistler='sim', whistler_params=[3,w,7.5,2.5,1,90], save=True)\n",
    "# data = my_detector.load_detector_metric(train=True, transforms=['zscore'], transforms_params=[[None]], detector='tm_cfar', \n",
    "#                             detector_params=[10,15,1e-3,0], diff_err=0.3, time_err=0.2, whistler='sim', whistler_params=[3,0.6,5,2.5,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2877, 200, 500)\n",
      "(2649, 428, 985)\n",
      "(1598, 1479, 466)\n",
      "(927, 2150, 689)\n",
      "(941, 2136, 790)\n",
      "(1239, 1838, 535)\n"
     ]
    }
   ],
   "source": [
    "for w in [0.5,0.65,0.8,1,1.5]:\n",
    "    data = my_detector.load_detector_metric(train=True, transforms=['zscore'], transforms_params=[[None]], detector='tm_cfar', \n",
    "                                detector_params=[10,15,1e-3,0], diff_err=0.3, time_err=0.2, whistler='sim', whistler_params=[w,0.8,7.5,2.5,1,90])\n",
    "    results = data['results']\n",
    "    print(my_detector.results(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp_gpu",
   "language": "python",
   "name": "dp_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
