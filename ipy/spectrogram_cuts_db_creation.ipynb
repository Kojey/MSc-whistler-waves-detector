{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "sys.path.insert(0,'../')\n",
    "sys.path.insert(0,'../py')\n",
    "\n",
    "import parameters\n",
    "import utilities\n",
    "from spectrogram_utilities import spectrogram_reshape\n",
    "import output_utilities\n",
    "import spectrogram_output_visualiser\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# tf.enable_eager_execution() \n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram_cuts_db(awd_event, site, files, database_name, \n",
    "                        threshold=parameters.output_threshold,\n",
    "                        time_lower_boundary = parameters.time_lower_boundary,\n",
    "                        time_upper_boundary = parameters.time_upper_boundary,\n",
    "                        freq_upper_boundary = parameters.freq_upper_boundary,\n",
    "                        freq_lower_boundary = parameters.freq_lower_boundary,\n",
    "                        verbose=False, force=False):\n",
    "    '''Extract the whistler and noise cuts and store them in a h5py database'''\n",
    "    start = time.time()\n",
    "\n",
    "    # create h5py database\n",
    "    if not utilities.init_h5py(database_name, force=force, verbose=verbose):\n",
    "        return \n",
    "    # load database\n",
    "    database = h5py.File(utilities.get_h5py_path(database_name), 'r+')\n",
    "\n",
    "    if verbose:\n",
    "        print('\\nGenerating whistler and noise cuts database for %s/%s' %('awdEvent'+str(awd_event),site))\n",
    "        last_percent = None\n",
    "        num_file = 0\n",
    "    for file in files:\n",
    "        indices, spectrogram, spec_cuts, noise_cuts, f_cut_length, t_cut_length = spectrogram_output_visualiser.spectrogram_cut(\n",
    "            awd_event, site, file, \n",
    "            threshold=threshold,\n",
    "            time_lower_boundary=time_lower_boundary,\n",
    "            time_upper_boundary=time_upper_boundary,\n",
    "            freq_upper_boundary=freq_upper_boundary,\n",
    "            freq_lower_boundary=freq_lower_boundary)\n",
    "        i = 0\n",
    "        for cut in spec_cuts:\n",
    "            spec = spectrogram[cut[0]:cut[1],cut[2]:cut[3]] # extract portion of interest in the spectrogram \n",
    "            # resize spec to fixed size\n",
    "#             spec = Image.fromarray(spec).resize((parameters.clf_input_width, parameters.clf_input_height))\n",
    "#             spec = np.array(spec)\n",
    "            spec = spectrogram_reshape(spec)\n",
    "            dataset_name = file.split(site)[0]+str(i)\n",
    "            file_dataset = database.create_dataset(dataset_name,spec.shape,np.float32, compression=\"gzip\", data=spec)\n",
    "            file_dataset.attrs['pb'] = int(indices[i][-1])\n",
    "            file_dataset.attrs['evt'] = True\n",
    "            file_dataset.attrs['site'] = site\n",
    "            i += 1\n",
    "        for noise in noise_cuts:\n",
    "            spec = spectrogram[noise[0]:noise[1], noise[2]:noise[3]]\n",
    "            # resize spec to fixed size\n",
    "#             spec = Image.fromarray(spec).resize((parameters.clf_input_width, parameters.clf_input_height))\n",
    "#             spec = np.array(spec)\n",
    "            spec = spectrogram_reshape(spec)\n",
    "            dataset_name = file.split(site)[0]+str(i)\n",
    "            file_dataset = database.create_dataset(dataset_name,spec.shape,np.float32, compression=\"gzip\", data=spec)\n",
    "            file_dataset.attrs['pb'] = 0\n",
    "            file_dataset.attrs['evt'] = False\n",
    "            file_dataset.attrs['site'] = site\n",
    "            i += 1\n",
    "        if verbose:\n",
    "            percent = int(num_file*100/len(files))\n",
    "            if last_percent != percent:\n",
    "                if percent%10==0:\n",
    "                    sys.stdout.write(\"%s%%\" % percent)\n",
    "                    sys.stdout.flush()\n",
    "                else:\n",
    "                    sys.stdout.write(\".\")\n",
    "                    sys.stdout.flush()\n",
    "                last_percent = percent\n",
    "            num_file+=1\n",
    "    database.attrs['freq_length']=f_cut_length\n",
    "    database.attrs['time_length']=t_cut_length\n",
    "    database.attrs['width']=parameters.clf_input_width\n",
    "    database.attrs['height']=parameters.clf_input_height\n",
    "    database.close()\n",
    "    end = time.time()\n",
    "    if verbose:\n",
    "        print(\"\\nRuntime: {:.2f} seconds\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spectrogram_cuts_db(awd_event, site, database_name, verbose=False, noise=True):\n",
    "    '''Load spectrogram cuts from database\n",
    "    returns:\n",
    "        array of spectrogram\n",
    "    '''\n",
    "    start = time.time()\n",
    "    data = []\n",
    "    pb = []\n",
    "    evt = []\n",
    "    _site = []\n",
    "    # load database\n",
    "    try:\n",
    "        database = h5py.File(utilities.get_h5py_path(database_name), 'r+')\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(e)\n",
    "        # if no database, create the database\n",
    "        files = utilities.all_files(awd_event, site)\n",
    "        spectrogram_cuts_db(awd_event, site, files, database_name,verbose=verbose)\n",
    "        start = time.time() # restart timing\n",
    "        database = h5py.File(utilities.get_h5py_path(database_name), 'r+')\n",
    "    files = list(database.keys())\n",
    "    if verbose:\n",
    "        print('\\nLoading spectrogram cuts from database for %s/%s' %('awdEvent'+str(awd_event),site))\n",
    "        last_percent = None\n",
    "        num_file = 0\n",
    "    for file in files:\n",
    "        if not noise and not database[file].attrs['evt']:\n",
    "            # if noise is not selected, skip the noise cut\n",
    "            \n",
    "            continue\n",
    "        file_data = np.empty(database[file].shape)\n",
    "        database[file].read_direct(file_data)\n",
    "        file_data = file_data.flatten()\n",
    "        data.append(file_data)\n",
    "        pb.append(database[file].attrs['pb'])\n",
    "        evt.append(database[file].attrs['evt'])\n",
    "        _site.append(database[file].attrs['site'])\n",
    "        if verbose:\n",
    "            percent = int(num_file*100/len(files))\n",
    "            if last_percent != percent:\n",
    "                if percent%10==0:\n",
    "                    sys.stdout.write(\"%s%%\" % percent)\n",
    "                    sys.stdout.flush()\n",
    "                else:\n",
    "                    sys.stdout.write(\".\")\n",
    "                    sys.stdout.flush()\n",
    "                last_percent = percent\n",
    "            num_file+=1\n",
    "    data = np.array(data)\n",
    "    pb = np.array(pb)\n",
    "    evt = np.array(evt)\n",
    "    f_cut_length = database.attrs['freq_length']\n",
    "    t_cut_length = database.attrs['time_length']\n",
    "    \n",
    "    database.close()\n",
    "    end = time.time()\n",
    "    if verbose:\n",
    "        print(\"\\nRuntime: {:.2f} seconds\".format(end - start))\n",
    "    return data, pb, evt, f_cut_length, t_cut_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram_cuts_tfrecords(awd_event, site,verbose=False):\n",
    "    '''Extract the whistler and noise cuts and store them in a TFRecords database'''\n",
    "    start = time.time()\n",
    "    files = utilities.all_files(awd_event, site)\n",
    "    if verbose:\n",
    "        print('\\nGenerating whistler and noise cuts tfrecord files for %s/%s' %('awdEvent'+str(awd_event),site))\n",
    "        last_percent = None\n",
    "        num_file = 0\n",
    "    for file in files:\n",
    "        indices, spectrogram, spec_cuts, noise_cuts, f_cut_length, t_cut_length = spectrogram_output_visualiser.spectrogram_cut(awd_event, site, file, 10)\n",
    "        i = 0\n",
    "        for cut in spec_cuts:\n",
    "            spec = spectrogram[cut[0]:cut[1],cut[2]:cut[3]] # extract portion of interest in the spectrogram \n",
    "            dataset_name = os.path.join(parameters.tfrecord_location,\n",
    "                                        'awdEvents1',\n",
    "                                        'cuts',\n",
    "                                os.path.splitext(file)[0]+'.1'+'_'+str(cut[0])+'_'+str(cut[1])+'_'+str(cut[2])+'_'+str(cut[3])+'.tfr')\n",
    "            # save whistler cut as a tf record\n",
    "            writer = tf.python_io.TFRecordWriter(dataset_name)\n",
    "            feature = {\n",
    "                'data': tf.train.Feature(\n",
    "                            float_list=tf.train.FloatList(value=spec.flatten())),\n",
    "                'merit': tf.train.Feature(\n",
    "                            int64_list=tf.train.Int64List(value=[int(indices[i][-1])])),\n",
    "                'label': tf.train.Feature(\n",
    "                            int64_list=tf.train.Int64List(value=[True]))\n",
    "            }\n",
    "            example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "            # serialize to string and write on the file\n",
    "            writer.write(example.SerializeToString())\n",
    "            writer.close()\n",
    "            i += 1\n",
    "        for cut in noise_cuts:\n",
    "            spec = spectrogram[cut[0]:cut[1],cut[2]:cut[3]]\n",
    "            dataset_name = os.path.join(parameters.tfrecord_location,\n",
    "                                        'awdEvents1',\n",
    "                                        'cuts',\n",
    "                                os.path.splitext(file)[0]+'.0'+'_'+str(cut[0])+'_'+str(cut[1])+'_'+str(cut[2])+'_'+str(cut[3])+'.tfr')\n",
    "#             print(dataset_name)\n",
    "            # save noise cut as a tf record\n",
    "            writer = tf.python_io.TFRecordWriter(dataset_name)\n",
    "            feature = {\n",
    "                'data': tf.train.Feature(\n",
    "                            float_list=tf.train.FloatList(value=spec.flatten())),\n",
    "                'merit': tf.train.Feature(\n",
    "                            int64_list=tf.train.Int64List(value=[0])),\n",
    "                'label': tf.train.Feature(\n",
    "                            int64_list=tf.train.Int64List(value=[False]))\n",
    "            }\n",
    "            example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "            # serialize to string and write on the file\n",
    "            writer.write(example.SerializeToString())\n",
    "            writer.close()\n",
    "            i += 1\n",
    "        if verbose:\n",
    "            percent = int(num_file*100/len(files))\n",
    "            if last_percent != percent:\n",
    "                if percent%10==0:\n",
    "                    sys.stdout.write(\"%s%%\" % percent)\n",
    "                    sys.stdout.flush()\n",
    "                else:\n",
    "                    sys.stdout.write(\".\")\n",
    "                    sys.stdout.flush()\n",
    "                last_percent = percent\n",
    "            num_file+=1\n",
    "    end = time.time()\n",
    "    if verbose:\n",
    "        print(\"\\nRuntime: {:.2f} seconds\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singular H5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram_cuts_h5py(awd_event, site,verbose=False):\n",
    "    '''Extract the whistler and noise cuts and store them in a h5py database'''\n",
    "    start = time.time()\n",
    "    files = utilities.all_files(awd_event, site)\n",
    "\n",
    "    if verbose:\n",
    "        print('\\nGenerating whistler and noise cuts database for %s/%s' %('awdEvent'+str(awd_event),site))\n",
    "        last_percent = None\n",
    "        num_file = 0\n",
    "    for file in files:\n",
    "        indices, spectrogram, spec_cuts, noise_cuts, f_cut_length, t_cut_length = spectrogram_output_visualiser.spectrogram_cut(awd_event, site, file, 10)\n",
    "        i = 0\n",
    "        for cut in spec_cuts:\n",
    "            spec = spectrogram[cut[0]:cut[1],cut[2]:cut[3]] # extract portion of interest in the spectrogram \n",
    "            dataset_name = os.path.join(parameters.hyp5_location,\n",
    "                                        'awdEvents1',\n",
    "                                        'cuts',\n",
    "                                os.path.splitext(file)[0]+'.1'+'_'+str(cut[0])+'_'+str(cut[1])+'_'+str(cut[2])+'_'+str(cut[3])+'.h5')\n",
    "            f = h5py.File(dataset_name, 'w')\n",
    "            file_dataset = f.create_dataset(dataset_name,spec.shape,np.float32, compression=\"gzip\", data=spec)\n",
    "            file_dataset.attrs['pb'] = int(indices[i][-1])\n",
    "            file_dataset.attrs['evt'] = True\n",
    "            file_dataset.attrs['freq_length']=f_cut_length\n",
    "            file_dataset.attrs['time_length']=t_cut_length\n",
    "            f.close()\n",
    "            i += 1\n",
    "        for noise in noise_cuts:\n",
    "            spec = spectrogram[noise[0]:noise[1], noise[2]:noise[3]]\n",
    "            dataset_name = os.path.join(parameters.hyp5_location,\n",
    "                                        'awdEvents1',\n",
    "                                        'cuts',\n",
    "                                os.path.splitext(file)[0]+'.0'+'_'+str(cut[0])+'_'+str(cut[1])+'_'+str(cut[2])+'_'+str(cut[3])+'.h5')\n",
    "            f = h5py.File(dataset_name, 'w')\n",
    "            file_dataset = f.create_dataset(dataset_name,spec.shape,np.float32, compression=\"gzip\", data=spec)\n",
    "            file_dataset.attrs['pb'] = 0\n",
    "            file_dataset.attrs['evt'] = False\n",
    "            file_dataset.attrs['freq_length']=f_cut_length\n",
    "            file_dataset.attrs['time_length']=t_cut_length\n",
    "            f.close()\n",
    "            i += 1\n",
    "        if verbose:\n",
    "            percent = int(num_file*100/len(files))\n",
    "            if last_percent != percent:\n",
    "                if percent%10==0:\n",
    "                    sys.stdout.write(\"%s%%\" % percent)\n",
    "                    sys.stdout.flush()\n",
    "                else:\n",
    "                    sys.stdout.write(\".\")\n",
    "                    sys.stdout.flush()\n",
    "                last_percent = percent\n",
    "            num_file+=1\n",
    "    end = time.time()\n",
    "    if verbose:\n",
    "        print(\"\\nRuntime: {:.2f} seconds\".format(end - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
