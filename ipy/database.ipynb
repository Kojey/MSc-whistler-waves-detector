{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATABASE CLASS\n",
    "_Represent the database create from the dataset of samples_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import h5py\n",
    "import glob\n",
    "import tqdm\n",
    "import time \n",
    "from texttable import Texttable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "\n",
    "# import python library\n",
    "sys.path.append(os.path.join(os.getcwd().split(os.environ.get('USER'))[0],os.environ.get('USER'), 'wdml', 'py'))\n",
    "\n",
    "from dataset import Dataset\n",
    "from sample import Sample\n",
    "\n",
    "\n",
    "class Database(Dataset):\n",
    "    # Attributes\n",
    "    \n",
    "    # Initializer\n",
    "    def __init__(self, dataset_location, database_location, site):\n",
    "        self.__database_location = database_location\n",
    "        super(Database, self).__init__(dataset_location, site)\n",
    "\n",
    "    def get_database_location(self):\n",
    "        return self.__database_location\n",
    "    \n",
    "    \n",
    "    def create_cut_db(self, sample):\n",
    "        '''Create a database from a single file'''\n",
    "        sample_obj = Sample(self.get_dataset_location(), self.get_site(), sample)\n",
    "        # cuts of 1s and 10kHz\n",
    "        cuts, whistler_count, cuts_count = sample_obj.cuts(cut_time=1, cut_freq=10, threshold=0)\n",
    "        for cut, ix in zip(cuts, range(cuts_count)) :\n",
    "            file_name = os.path.join(self.__database_location,self.get_site(),\n",
    "                                        os.path.splitext(sample)[0]+'.cut_nbr:'+\"{:02d}\".format(ix+1)+'.evt:'+str(ix<whistler_count)+'.['+str(cut[0])+':'+str(cut[1])+','+str(cut[2])+':'+str(cut[3])+'].h5')\n",
    "            file = h5py.File(file_name, 'w')\n",
    "            spec = sample_obj.get_spectrogram()[cut[0]:cut[1],cut[2]:cut[3]]\n",
    "            file_dataset = file.create_dataset(file_name, spec.shape, np.float32, compression='gzip', data=spec)\n",
    "            file_dataset.attrs['target'] = ix<whistler_count\n",
    "            file.close()\n",
    "\n",
    "    def create_cuts_db(self):\n",
    "        ''''''\n",
    "        samples = self.get_samples_name()\n",
    "        try:\n",
    "            os.makedirs(os.path.join(self.__database_location,self.get_site()))\n",
    "        except OSError:\n",
    "            pass\n",
    "        for sample in tqdm.tqdm(samples):\n",
    "            self.create_cut_db(sample)\n",
    "          \n",
    "            \n",
    "    def create_cuts_db_mp(self, verbose=True):\n",
    "        '''Parallel implementation of create_cuts_dp'''\n",
    "        samples = self.get_samples_name()\n",
    "        try:\n",
    "            os.makedirs(os.path.join(self.__database_location,self.get_site()))\n",
    "        except OSError:\n",
    "            pass\n",
    "        pool = mp.Pool(mp.cpu_count())\n",
    "        if verbose:\n",
    "            for _ in tqdm.tqdm(pool.imap_unordered(self.create_cut_db, samples), total=len(samples)):\n",
    "                pass\n",
    "        else:\n",
    "            pool.map_async(self.create_cut_db, samples)\n",
    "        pool.close()\n",
    "    \n",
    "    def load_cut_db(self, sample):\n",
    "        '''Load one cut from the database'''\n",
    "        file = h5py.File(sample, 'r+')\n",
    "        file_data = np.empty(file[sample].shape)\n",
    "        file[sample].read_direct(file_data)\n",
    "        cut = np.asarray(file_data)\n",
    "        target = file[sample].attrs['target']\n",
    "        file.close()\n",
    "        return cut, target\n",
    "            \n",
    "    \n",
    "    def load_cuts_db(self):\n",
    "        ''''''\n",
    "        try:\n",
    "            samples = glob.glob(os.path.join(self.__database_location,self.get_site(), '*.h5'))\n",
    "        except OSError:\n",
    "            return None, None\n",
    "        cuts, targets = [], []\n",
    "        for sample in tqdm.tqdm(samples):\n",
    "            cut, target = self.load_cut_db(sample)\n",
    "            cuts.append(cut)\n",
    "            targets.append(target)\n",
    "        return np.array(cuts), np.array(targets)\n",
    "\n",
    "    def load_cuts_db_mp(self, verbose=True):\n",
    "        ''''''\n",
    "        try:\n",
    "            samples = glob.glob(os.path.join(self.__database_location,self.get_site(), '*.h5'))\n",
    "        except OSError:\n",
    "            return None, None\n",
    "        pool = mp.Pool(mp.cpu_count())\n",
    "        if verbose:\n",
    "            results = []\n",
    "            for result in tqdm.tqdm(pool.imap_unordered(self.load_cut_db, samples), total=len(samples)):\n",
    "                results.append(result)\n",
    "            results = np.array(results)\n",
    "        else:\n",
    "            results = np.array(pool.map_async(self.load_cut_db, samples).get())\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        return np.array(results[:,0]), np.array(results[:,1], dtype=np.bool_)\n",
    "    \n",
    "    def stats(self):\n",
    "        '''Database stats'''\n",
    "        cuts, targets = self.load_cuts_db_mp()\n",
    "        temp = []\n",
    "        temp.append([cut.flatten() for cut in cuts])\n",
    "        cuts = np.array(temp)\n",
    "        cuts = cuts.flatten()\n",
    "        counts = np.bincount(targets)\n",
    "        counts_per = np.round(np.bincount(targets)*100/len(targets),2)\n",
    "        \n",
    "        table = Texttable()\n",
    "        table.set_deco(Texttable.HEADER)\n",
    "        table.set_header_align(['l','m','m'])\n",
    "        table.header(['Database statistics', '',''])\n",
    "        table.set_cols_align(['l','l','l'])\n",
    "        table.set_cols_valign(['m','m','m'])\n",
    "        table.add_rows([\n",
    "                ['min',cuts.min()],\n",
    "                ['max',cuts.max()],\n",
    "                ['mean',cuts.mean()],\n",
    "                ['std',cuts.std()],\n",
    "                ['noise', str(counts[0])+'['+str(counts_per[0])+'%]'],\n",
    "                ['whistler', str(counts[1])+'['+str(counts_per[1])+'%]'],\n",
    "                ['total', len(targets)]], header=False)\n",
    "        print('\\n'+ table.draw() + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27004/27004 [02:52<00:00, 248.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Database statistics                  \n",
      "=====================================\n",
      "noise                 53.88%   14549 \n",
      "whistler              46.12%   12455 \n",
      "total                          27004 \n",
      "min                            -4.673\n",
      "max                            4.120 \n",
      "mean                           1.445 \n",
      "std                            0.519 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([14549, 12455])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset_loc = os.path.join(os.getcwd().split(os.environ.get('USER'))[0],os.environ.get('USER'), 'wdml', 'data','datasets', 'awdEvents1')\n",
    "# database_loc = os.path.join(os.getcwd().split(os.environ.get('USER'))[0],os.environ.get('USER'), 'wdml', 'data','databases', 'awdEvents1')\n",
    "# site = 'marion'\n",
    "# my_database = Database(dataset_loc, database_loc, site)\n",
    "\n",
    "# my_database.create_cuts_db_mp(verbose=True)\n",
    "# cuts, targets = my_database.load_cuts_db_mp()\n",
    "# my_database.stats(verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp_gpu",
   "language": "python",
   "name": "dp_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
